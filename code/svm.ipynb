{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('./final_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "keyword       0\n",
       "location      0\n",
       "text          0\n",
       "target        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22616, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>Our Deeds are the Reason of this earthquake Ma...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>Forest fire near La Ronge Sask Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>All residents asked to shelter in place are be...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>people receive wildfires evacuation orders in ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>no_keyword</td>\n",
       "      <td>no_location</td>\n",
       "      <td>Just got sent this photo from Ruby Alaska as s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0     keyword     location  \\\n",
       "0           0  no_keyword  no_location   \n",
       "1           1  no_keyword  no_location   \n",
       "2           2  no_keyword  no_location   \n",
       "3           3  no_keyword  no_location   \n",
       "4           4  no_keyword  no_location   \n",
       "\n",
       "                                                text  target  \n",
       "0  Our Deeds are the Reason of this earthquake Ma...       1  \n",
       "1              Forest fire near La Ronge Sask Canada       1  \n",
       "2  All residents asked to shelter in place are be...       1  \n",
       "3  people receive wildfires evacuation orders in ...       1  \n",
       "4  Just got sent this photo from Ruby Alaska as s...       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train, Validation, Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "X = df.text\n",
    "y = df.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13569,)\n",
      "(4523,)\n",
      "(4524,)\n",
      "(13569,)\n",
      "(4523,)\n",
      "(4524,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_val.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8432456334291399\n",
      "training accuracy: 0.9372098164934778\n",
      "test accuracy: 0.8437223695844386\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_df and max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 0.0 validation accuracy: 0.8432456334291399\n",
      "min_df: 0.2 validation accuracy: 0.7441963298695556\n",
      "min_df: 0.4 validation accuracy: 0.7426486845014371\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i in np.arange(0.0, 0.6, 0.2):\n",
    "    vect = CountVectorizer(min_df = i)\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    X_val_dtm = vect.transform(X_val)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('min_df:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 1 validation accuracy: 0.8432456334291399\n",
      "min_df: 2 validation accuracy: 0.8416979880610215\n",
      "min_df: 3 validation accuracy: 0.8423612646473579\n",
      "min_df: 4 validation accuracy: 0.8432456334291399\n",
      "min_df: 5 validation accuracy: 0.842803449038249\n",
      "min_df: 6 validation accuracy: 0.841476895865576\n",
      "min_df: 7 validation accuracy: 0.8425823568428035\n",
      "min_df: 8 validation accuracy: 0.841476895865576\n",
      "min_df: 9 validation accuracy: 0.8408136192792395\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    vect = CountVectorizer(min_df = i)\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    X_val_dtm = vect.transform(X_val)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('min_df:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df: 1.0 validation accuracy: 0.8432456334291399\n",
      "max_df: 0.8 validation accuracy: 0.8432456334291399\n",
      "max_df: 0.6000000000000001 validation accuracy: 0.8432456334291399\n",
      "max_df: 0.40000000000000013 validation accuracy: 0.8439089100154764\n",
      "max_df: 0.20000000000000018 validation accuracy: 0.8439089100154764\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1.0, 0.0, -0.2):\n",
    "    vect = CountVectorizer(max_df = i)\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    X_val_dtm = vect.transform(X_val)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('max_df:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest validation accuracy when setting max_df=0.4 (0.8439), tuning min_df did not help to improve validation accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lowercase = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8377183285430024\n",
      "training accuracy: 0.9382415800722235\n",
      "test accuracy: 0.8370910698496905\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(lowercase=False)\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_df and max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 1 validation accuracy: 0.8377183285430024\n",
      "min_df: 2 validation accuracy: 0.837055051956666\n",
      "min_df: 3 validation accuracy: 0.8368339597612204\n",
      "min_df: 4 validation accuracy: 0.8363917753703294\n",
      "min_df: 5 validation accuracy: 0.8368339597612204\n",
      "min_df: 6 validation accuracy: 0.8341808534158744\n",
      "min_df: 7 validation accuracy: 0.8330753924386469\n",
      "min_df: 8 validation accuracy: 0.8324121158523105\n",
      "min_df: 9 validation accuracy: 0.8319699314614194\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    vect = CountVectorizer(lowercase=False, min_df = i)\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    X_val_dtm = vect.transform(X_val)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('min_df:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df: 1.0 validation accuracy: 0.8377183285430024\n",
      "max_df: 0.8 validation accuracy: 0.8377183285430024\n",
      "max_df: 0.6000000000000001 validation accuracy: 0.8377183285430024\n",
      "max_df: 0.40000000000000013 validation accuracy: 0.8377183285430024\n",
      "max_df: 0.20000000000000018 validation accuracy: 0.8368339597612204\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1.0, 0.0, -0.2):\n",
    "    vect = CountVectorizer(lowercase=False, max_df = i)\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    X_val_dtm = vect.transform(X_val)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('max_df:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning min_df and max_df did not help to improve validation accuracy. From CountVectorizer() and CountVectorizer(lowercase=False), we can see that tuning min_df and max_df did not help much in improving validation accuracy. Even for CountrVectorizer(), setting max_df=0.4 only increase the validation accuracy by less than 0.1% (from 0.8432 to 0.8439). Currently, the highest validation accuracy is achieved by setting CountVectorizer(max_df=0.4), subsequently, if the validation accuracy is not higher, we will not be tuning on min_df and max_df."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stopword = english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.83882378952023\n",
      "training accuracy: 0.9520966909868082\n",
      "test accuracy: 0.8384173297966402\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english')\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lowercase=False, stopwords=english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8372761441521114\n",
      "training accuracy: 0.9522440857837718\n",
      "test accuracy: 0.8348806366047745\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(stop_words='english', lowercase=False)\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ngram=(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8410347114746849\n",
      "training accuracy: 0.9523914805807355\n",
      "test accuracy: 0.8408488063660478\n"
     ]
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Default TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.851204952465178\n",
      "training accuracy: 0.9691207900361117\n",
      "test accuracy: 0.8516799292661361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning min_df and max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_df: 1 validation accuracy: 0.851204952465178\n",
      "min_df: 2 validation accuracy: 0.8518682290515145\n",
      "min_df: 3 validation accuracy: 0.850320583683396\n",
      "min_df: 4 validation accuracy: 0.849436214901614\n",
      "min_df: 5 validation accuracy: 0.8485518461198319\n",
      "min_df: 6 validation accuracy: 0.8456776475790405\n",
      "min_df: 7 validation accuracy: 0.8476674773380499\n",
      "min_df: 8 validation accuracy: 0.8485518461198319\n",
      "min_df: 9 validation accuracy: 0.8485518461198319\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    vect =TfidfVectorizer(min_df=i)\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    X_val_dtm = vect.transform(X_val)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('min_df:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_df: 1.0 validation accuracy: 0.851204952465178\n",
      "max_df: 0.8 validation accuracy: 0.851204952465178\n",
      "max_df: 0.6000000000000001 validation accuracy: 0.851204952465178\n",
      "max_df: 0.40000000000000013 validation accuracy: 0.850762768074287\n",
      "max_df: 0.20000000000000018 validation accuracy: 0.8492151227061685\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1.0, 0.0, -0.2):\n",
    "    vect =TfidfVectorizer(max_df=i)\n",
    "    vect.fit(X_train)\n",
    "    X_train_dtm = vect.transform(X_train)\n",
    "    X_val_dtm = vect.transform(X_val)\n",
    "    X_test_dtm = vect.transform(X_test)\n",
    "    svc = SVC()\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('max_df:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lowercase=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8483307539243865\n",
      "training accuracy: 0.9719212911784214\n",
      "test accuracy: 0.8428381962864722\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(lowercase=False)\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stopwords=english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8432456334291399\n",
      "training accuracy: 0.9708895275996757\n",
      "test accuracy: 0.8448275862068966\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(stop_words='english')\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ngram=(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8461198319699315\n",
      "training accuracy: 0.98231262436436\n",
      "test accuracy: 0.8443854995579133\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "svc = SVC()\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tuning SVC()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using vect=TfidfVectorizer(), which gave us the highest validation accrucay in the tuning process (0.8512)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vect = TfidfVectorizer()\n",
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_val_dtm = vect.transform(X_val)\n",
    "X_test_dtm = vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8467831085562679\n",
      "training accuracy: 0.8974132213132876\n",
      "test accuracy: 0.8474801061007957\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='sigmoid')\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.7426486845014371\n",
      "training accuracy: 0.7381531431940452\n",
      "test accuracy: 0.7431476569407603\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=0.1)\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.8562900729604245\n",
      "training accuracy: 0.9991893286166998\n",
      "test accuracy: 0.8510167992926614\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=10)\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regulariaztion: 1 validation accuracy: 0.851204952465178\n",
      "regulariaztion: 2 validation accuracy: 0.857837718328543\n",
      "regulariaztion: 3 validation accuracy: 0.8576166261330975\n",
      "regulariaztion: 4 validation accuracy: 0.8562900729604245\n",
      "regulariaztion: 5 validation accuracy: 0.85651116515587\n",
      "regulariaztion: 6 validation accuracy: 0.8562900729604245\n",
      "regulariaztion: 7 validation accuracy: 0.85651116515587\n",
      "regulariaztion: 8 validation accuracy: 0.8567322573513155\n",
      "regulariaztion: 9 validation accuracy: 0.8567322573513155\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    svc = SVC(C=i)\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('regulariaztion:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regulariaztion: 1.0 validation accuracy: 0.851204952465178\n",
      "regulariaztion: 1.1 validation accuracy: 0.8536369666150785\n",
      "regulariaztion: 1.2000000000000002 validation accuracy: 0.855184611983197\n",
      "regulariaztion: 1.3000000000000003 validation accuracy: 0.855184611983197\n",
      "regulariaztion: 1.4000000000000004 validation accuracy: 0.8558478885695335\n",
      "regulariaztion: 1.5000000000000004 validation accuracy: 0.857395533937652\n",
      "regulariaztion: 1.6000000000000005 validation accuracy: 0.8585009949148795\n",
      "regulariaztion: 1.7000000000000006 validation accuracy: 0.858722087110325\n",
      "regulariaztion: 1.8000000000000007 validation accuracy: 0.857395533937652\n",
      "regulariaztion: 1.9000000000000008 validation accuracy: 0.858279902719434\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(1.0,2.0,0.1):\n",
    "    svc = SVC(C=i)\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('regulariaztion:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "regulariaztion: 0.1 validation accuracy: 0.7426486845014371\n",
      "regulariaztion: 0.2 validation accuracy: 0.7548087552509396\n",
      "regulariaztion: 0.30000000000000004 validation accuracy: 0.7879725845677648\n",
      "regulariaztion: 0.4 validation accuracy: 0.8129560026531063\n",
      "regulariaztion: 0.5 validation accuracy: 0.8260004421843908\n",
      "regulariaztion: 0.6 validation accuracy: 0.8355074065885474\n",
      "regulariaztion: 0.7000000000000001 validation accuracy: 0.8421401724519124\n",
      "regulariaztion: 0.8 validation accuracy: 0.8470042007517135\n",
      "regulariaztion: 0.9 validation accuracy: 0.8485518461198319\n"
     ]
    }
   ],
   "source": [
    "for i in np.arange(0.1,1.0,0.1):\n",
    "    svc = SVC(C=i)\n",
    "    svc.fit(X_train_dtm, y_train)\n",
    "    print('regulariaztion:', i, 'validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.858722087110325\n",
      "training accuracy: 0.9959466430834991\n",
      "test accuracy: 0.8538903625110522\n"
     ]
    }
   ],
   "source": [
    "# with TfidfiVectorizer()\n",
    "svc = SVC(C=1.7)\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6659929257200606"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1 score\n",
    "y_pred_class = svc.predict(X_test_dtm)\n",
    "metrics.f1_score(y_test, y_pred_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse FP and FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17635         donate the funds to the Australia wild fires\n",
       "22252    MetropolitanPolice hunt man charged with sexua...\n",
       "12462    We were called to food truck alight on Canvey ...\n",
       "5066     Reddit Will Now Quarantine Offensive onlinecom...\n",
       "3505                                            Im On Fire\n",
       "                               ...                        \n",
       "16349    BREAKING SUSPECTED IRANIAN SUICIDE BOMBER HEAD...\n",
       "22227    katrinabhaydon Police said first words in the ...\n",
       "22404    couple years ago in Ukraine there were well ov...\n",
       "18098    RT drnickgreiner Were in headlong retreat and ...\n",
       "20256    RT If you were silent when the same Myanmar mi...\n",
       "Name: text, Length: 158, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False positive\n",
    "X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "donate the funds to the Australia wild fires\n",
      "Reddit Will Now Quarantine Offensive onlinecommunities reddit amageddon freespeech\n",
      "Im On Fire\n",
      "RT drnickgreiner Were in headlong retreat and the rearguard is getting annihilated by enthemy fire\n",
      "RT If you were silent when the same Myanmar military committed Genocide against the Rohingya amp displaced over million of ththem under dthemocratically elected government then youre Hypocrite\n"
     ]
    }
   ],
   "source": [
    "print(X_test[17635]) #fire\n",
    "print(X_test[5066]) #quarantine\n",
    "print(X_test[3505]) #fire\n",
    "print(X_test[18098]) #fire\n",
    "print(X_test[20256]) #Myanmar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15432    What is that like times in as many months that...\n",
       "14532    Hillary Clinton If Im President We Will Attack...\n",
       "1830     GREAT CONDITION Easton Cyclone Softball Bat Fa...\n",
       "13491    USA Given the vulnerabilities of PuertoRico el...\n",
       "1541     xDescry was wrong to call it trusty actually c...\n",
       "                               ...                        \n",
       "5245     AHMazing story of the power animal rescuers ha...\n",
       "1280     Bush Fires are scaryeven scarier when you go d...\n",
       "2785     Believe it or not weve had too MUCH rain here ...\n",
       "7608     Islamic Jihadist mob attacked Hindus looted am...\n",
       "345      AP what violent country get the army involved ...\n",
       "Name: text, Length: 503, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# False negative\n",
    "X_test[y_test > y_pred_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is that like times in as many months that massive rioting halted major repressive or austerity measure Leb\n",
      "GREAT CONDITION Easton Cyclone Softball Bat Fastpitch\n",
      "USA Given the vulnerabilities of PuertoRico electric grid after Hurricane Maria the EDF says there is an urge\n",
      "xDescry was wrong to call it trusty actually considering it spontaneously collapsed on me thats not very trusty\n",
      "AHMazing story of the power animal rescuers have starving homeless dog with no future was rescued by person\n",
      "Bush Fires are scaryeven scarier when you go down and fight ththem\n",
      "Believe it or not weve had too MUCH rain here Our newly planted maple trees are actually drowning\n",
      "Islamic Jihadist mob attacked Hindus looted amp burnt Houses amp their property in Bhainsa town of Nirmal distTelangana la\n",
      "AP what violent country get the army involved to help control the killings and bring back peace to the poor people\n"
     ]
    }
   ],
   "source": [
    "print(X_test[15432]) #riot\n",
    "print(X_test[1830]) #mislabel\n",
    "print(X_test[13491]) \n",
    "print(X_test[1541]) \n",
    "print(X_test[5245]) #rescue, animal\n",
    "print(X_test[1280]) \n",
    "print(X_test[2785]) #rain, drowning \n",
    "print(X_test[7608]) \n",
    "print(X_test[345]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get AUC setting probability=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation accuracy: 0.858722087110325\n",
      "training accuracy: 0.9959466430834991\n",
      "test accuracy: 0.8538903625110522\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(C=1.7, probability=True, random_state=1)\n",
    "svc.fit(X_train_dtm, y_train)\n",
    "print('validation accuracy:', metrics.accuracy_score(y_val, svc.predict(X_val_dtm)))\n",
    "print('training accuracy:', metrics.accuracy_score(y_train, svc.predict(X_train_dtm)))\n",
    "print('test accuracy:', metrics.accuracy_score(y_test, svc.predict(X_test_dtm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8696594826659405"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob = svc.predict_proba(X_test_dtm)[:, 1]\n",
    "metrics.roc_auc_score(y_test, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
